# Data Engineering ‚Äî –†–∞–∑–¥–µ–ª 5. Airflow –∏ Kafka

**–ê–≤—Ç–æ—Ä:** –©–µ–≥–æ–ª–µ–≤ –ú–∏—Ö–∞–∏–ª  
**–ö—É—Ä—Å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –¥–ª—è –ª–∏—á–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, 2025**

---

## üìò –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ –≤ Apache Airflow](#–≤–≤–µ–¥–µ–Ω–∏–µ-–≤-apache-airflow)
2. [–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ DAG, Operators, Sensors, Hooks](#–æ—Å–Ω–æ–≤–Ω—ã–µ-–∫–æ–Ω—Ü–µ–ø—Ü–∏–∏-dag-operators-sensors-hooks)
3. [–ü–µ—Ä–µ–¥–∞—á–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ (XCom)](#–ø–µ—Ä–µ–¥–∞—á–∞-–¥–∞–Ω–Ω—ã—Ö-–º–µ–∂–¥—É-–∑–∞–¥–∞—á–∞–º–∏-xcom)
4. [Kafka ‚Äî –æ—Å–Ω–æ–≤—ã –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏](#kafka--–æ—Å–Ω–æ–≤—ã-–ø–æ—Ç–æ–∫–æ–≤–æ–π-–æ–±—Ä–∞–±–æ—Ç–∫–∏)
5. [–ú–∏–Ω–∏-–ø—Ä–æ–µ–∫—Ç: –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Kafka ‚Üí Spark ‚Üí DWH](#–º–∏–Ω–∏–ø—Ä–æ–µ–∫—Ç-–ø–æ—Ç–æ–∫–æ–≤–∞—è-–æ–±—Ä–∞–±–æ—Ç–∫–∞-kafka--spark--dwh)
6. [–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ GPT-–ø–æ–¥—Å–∫–∞–∑–∫–∏](#–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ-–≤–æ–ø—Ä–æ—Å—ã-–∏-gpt–ø–æ–¥—Å–∫–∞–∑–∫–∏)

---

## –í–≤–µ–¥–µ–Ω–∏–µ –≤ Apache Airflow

üìò –ú–∞—Ç–µ—Ä–∏–∞–ª—ã: *Index ‚Äî Roadmappers (Airflow)*  

### üß† –ß—Ç–æ —Ç–∞–∫–æ–µ Airflow
Apache Airflow ‚Äî –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —Å–æ–∑–¥–∞–≤–∞—Ç—å, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á (pipelines).

### üí° –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- **DAG (Directed Acyclic Graph)** ‚Äî –≥—Ä–∞—Ñ –∑–∞–¥–∞—á, –æ–ø–∏—Å—ã–≤–∞—é—â–∏–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.  
- **Task** ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è –∑–∞–¥–∞—á–∞ –≤–Ω—É—Ç—Ä–∏ DAG.  
- **Scheduler** ‚Äî –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.  
- **Executor** ‚Äî –º–µ—Ö–∞–Ω–∏–∑–º –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á (Local, Celery, Kubernetes).

### üíª –ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–≥–æ DAG

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def hello_world():
    print("Hello from Airflow!")

dag = DAG(
    'example_dag',
    start_date=datetime(2025, 1, 1),
    schedule_interval='@daily',
    catchup=False
)

task = PythonOperator(
    task_id='print_hello',
    python_callable=hello_world,
    dag=dag
)
```

üí° *–°–æ–≤–µ—Ç:* –∫–∞–∂–¥—ã–π DAG ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ Python-—Å–∫—Ä–∏–ø—Ç.

---

## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ DAG, Operators, Sensors, Hooks

### üß† –¢–µ—Ä–º–∏–Ω—ã
- **Operator** ‚Äî –∫–ª–∞—Å—Å, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π –∑–∞–¥–∞—á—É (PythonOperator, BashOperator, DummyOperator).  
- **Sensor** ‚Äî –æ–∂–∏–¥–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—è–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞).  
- **Hook** ‚Äî –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –≤–Ω–µ—à–Ω–∏–º —Å–∏—Å—Ç–µ–º–∞–º (PostgresHook, S3Hook).  
- **Dataset** ‚Äî –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö, —Å–≤—è–∑—ã–≤–∞—é—â–∏–π DAG-–∏ –º–µ–∂–¥—É —Å–æ–±–æ–π.

### üíª –ü—Ä–∏–º–µ—Ä —Å Sensor –∏ Hook

```python
from airflow.sensors.filesystem import FileSensor
from airflow.providers.postgres.hooks.postgres import PostgresHook

def load_to_db():
    hook = PostgresHook(postgres_conn_id='pg_connection')
    conn = hook.get_conn()
    cur = conn.cursor()
    cur.execute("INSERT INTO logs VALUES (now(), 'file_loaded')")
    conn.commit()

wait_for_file = FileSensor(
    task_id='wait_for_input',
    filepath='/data/input.csv',
    poke_interval=60,
    timeout=600,
    dag=dag
)
```

### üí° GPT-–ø–æ–¥—Å–∫–∞–∑–∫–∏
> –û–±—ä—è—Å–Ω–∏, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç Sensors –≤ Airflow.  
> –ö–∞–∫ —Å –ø–æ–º–æ—â—å—é Hook –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ S3 –∏ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª?

---

## –ü–µ—Ä–µ–¥–∞—á–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ (XCom)

### üß† –¢–µ–æ—Ä–∏—è
**XCom (Cross-Communication)** ‚Äî –º–µ—Ö–∞–Ω–∏–∑–º –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ DAG.

### üíª –ü—Ä–∏–º–µ—Ä

```python
def extract(**context):
    data = {"user_count": 42}
    context['ti'].xcom_push(key='data', value=data)

def transform(**context):
    data = context['ti'].xcom_pull(key='data')
    print(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

extract_task = PythonOperator(
    task_id='extract',
    python_callable=extract,
    provide_context=True,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform',
    python_callable=transform,
    provide_context=True,
    dag=dag
)

extract_task >> transform_task
```

### üí° GPT-–ø–æ–¥—Å–∫–∞–∑–∫–∏
> –ü–æ–ø—Ä–æ—Å–∏ GPT: ¬´–ö–∞–∫ –ª—É—á—à–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ –æ–±—ä—ë–º—ã –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ –≤ Airflow?¬ª  
> ¬´–ß–µ–º XCom –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç Dataset?¬ª

---

## Kafka ‚Äî –æ—Å–Ω–æ–≤—ã –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

üìò –ú–∞—Ç–µ—Ä–∏–∞–ª—ã: *Index ‚Äî Roadmappers (Kafka)*  

### üß† –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è
- **Producer** ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Kafka.  
- **Consumer** ‚Äî —á–∏—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Kafka.  
- **Topic** ‚Äî –∫–∞–Ω–∞–ª, –∫—É–¥–∞ –ø—É–±–ª–∏–∫—É—é—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è.  
- **Partition** ‚Äî –¥–µ–ª–µ–Ω–∏–µ —Ç–æ–ø–∏–∫–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.  
- **Offset** ‚Äî –ø–æ–∑–∏—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø–∞—Ä—Ç–∏—Ü–∏–∏.  
- **Retention** ‚Äî –≤—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 7 –¥–Ω–µ–π).  

### üíª –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–¥—é—Å–µ—Ä–∞ –∏ –∫–æ–Ω—Å—å—é–º–µ—Ä–∞

```python
# Producer
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

producer.send('sales_topic', {'user': 'mike', 'amount': 250})
producer.flush()

# Consumer
from kafka import KafkaConsumer

consumer = KafkaConsumer(
    'sales_topic',
    bootstrap_servers=['localhost:9092'],
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    value_deserializer=lambda v: json.loads(v.decode('utf-8'))
)

for msg in consumer:
    print(msg.value)
```

### üí° GPT-–ø–æ–¥—Å–∫–∞–∑–∫–∏
> –û–±—ä—è—Å–Ω–∏, –∑–∞—á–µ–º –Ω—É–∂–Ω—ã –ø–∞—Ä—Ç–∏—Ü–∏–∏ –≤ Kafka.  
> –ß—Ç–æ —Ç–∞–∫–æ–µ –ª–æ–≥ —Ä–µ—Ç–µ–Ω—à–Ω –∏ –∫–∞–∫ –µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å?  
> –ü—Ä–∏–¥—É–º–∞–π –∑–∞–¥–∞—á—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–æ–Ω—Å—å—é–º–µ—Ä–∞–º–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–ø–∏–∫–∞.

---

## –ú–∏–Ω–∏-–ø—Ä–æ–µ–∫—Ç: –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Kafka ‚Üí Spark ‚Üí DWH

### üéØ –¶–µ–ª—å
–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω, –∫–æ—Ç–æ—Ä—ã–π:
1. –ß–∏—Ç–∞–µ—Ç –ø–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Kafka (—Ç–æ–ø–∏–∫ `sales_topic`).  
2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö –≤ Spark Streaming.  
3. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ DWH.

### üíª –ü—Ä–∏–º–µ—Ä

```python
# Spark Streaming consumer
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("KafkaToDWH").getOrCreate()

df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "sales_topic") \
    .load()

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è
df_parsed = df.selectExpr("CAST(value AS STRING)")

agg = df_parsed.groupBy("region").count()

# –ó–∞–ø–∏—Å—å –≤ DWH (Postgres)
agg.writeStream \
    .outputMode("complete") \
    .format("jdbc") \
    .option("url", "jdbc:postgresql://localhost:5432/dwh") \
    .option("dbtable", "sales_summary") \
    .option("user", "airflow") \
    .option("password", "secret") \
    .start()
```

üí° *–°–æ–≤–µ—Ç:* –≠—Ç–æ—Ç –ø–∞–π–ø–ª–∞–π–Ω –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –∏–∑ Airflow DAG —á–µ—Ä–µ–∑ `SparkSubmitOperator`.

### üí° GPT-–ø–æ–¥—Å–∫–∞–∑–∫–∏
> –ü–æ–ø—Ä–æ—Å–∏ GPT –Ω–∞–ø–∏—Å–∞—Ç—å Airflow DAG, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–ø—É—Å–∫–∞–µ—Ç —ç—Ç–æ—Ç Spark Streaming job.  
> –î–æ–±–∞–≤—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –ø—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏ Kafka-–∫–æ–Ω–Ω–µ–∫—Ç–∞.

---

## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ GPT-–ø–æ–¥—Å–∫–∞–∑–∫–∏

1. –ß—Ç–æ —Ç–∞–∫–æ–µ DAG –∏ —á–µ–º –æ–Ω –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç Task?  
2. –ö–∞–∫–∏–µ —Ç–∏–ø—ã –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ Airflow?  
3. –ß—Ç–æ –¥–µ–ª–∞–µ—Ç Sensor –∏ –≤ –∫–∞–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –æ–Ω –ø–æ–ª–µ–∑–µ–Ω?  
4. –ß—Ç–æ —Ç–∞–∫–æ–µ XCom –∏ –∫–∞–∫ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è?  
5. –ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Kafka (Producer, Broker, Consumer)?  
6. –ß—Ç–æ —Ç–∞–∫–æ–µ –ø–∞—Ä—Ç–∏—Ü–∏–∏ –∏ –∑–∞—á–µ–º –æ–Ω–∏ –Ω—É–∂–Ω—ã?  
7. –ß—Ç–æ —Ç–∞–∫–æ–µ –ª–æ–≥ —Ä–µ—Ç–µ–Ω—à–Ω?  
8. –ö–∞–∫–∏–µ —Ç–∏–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Kafka?

üí° *–°–æ–≤–µ—Ç:* –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —Å–ø—Ä–æ—Å–∏ GPT:  
> ¬´–û–±—ä—è—Å–Ω–∏ –ø–æ—à–∞–≥–æ–≤–æ, –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ Kafka –∏ Airflow DAG¬ª  
> ¬´–ü—Ä–∏–¥—É–º–∞–π –∑–∞–¥–∞—á—É –ø–æ –æ–±–º–µ–Ω—É –¥–∞–Ω–Ω—ã–º–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ –≤ Airflow¬ª

---

‚úÖ **–ò—Ç–æ–≥ —Ä–∞–∑–¥–µ–ª–∞:**  
- –û—Å–≤–æ–µ–Ω—ã –ø—Ä–∏–Ω—Ü–∏–ø—ã –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –≤ Airflow.  
- –ü–æ–Ω–∏–º–∞–µ—à—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Kafka –∏ —É–º–µ–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å —Å –ø–æ—Ç–æ–∫–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö.  
- –ì–æ—Ç–æ–≤ –∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—é end-to-end –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ (Kafka ‚Üí Spark ‚Üí DWH).
